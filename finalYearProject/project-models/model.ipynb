{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:38.858382Z",
     "start_time": "2025-01-23T15:55:38.825164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "heart_data = pd.read_csv('./heart_disease_dataset/processed.cleveland.csv')\n",
    "\n",
    "heart_data.dropna()\n",
    "heart_data.head()\n",
    "heart_data.shape\n",
    "# heart_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:39.351473Z",
     "start_time": "2025-01-23T15:55:39.133978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   age        303 non-null    float64\n",
      " 1   sex        303 non-null    float64\n",
      " 2   cp         303 non-null    float64\n",
      " 3   trestbps   303 non-null    float64\n",
      " 4   chol       303 non-null    float64\n",
      " 5   fbs        303 non-null    float64\n",
      " 6   restecg    303 non-null    float64\n",
      " 7   thalach    303 non-null    float64\n",
      " 8   exang      303 non-null    float64\n",
      " 9   oldpeak    303 non-null    float64\n",
      " 10  slope      303 non-null    float64\n",
      " 11  ca         303 non-null    object \n",
      " 12  thal       303 non-null    object \n",
      " 13  condition  303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = heart_data.drop(columns='condition')   # Replace 'target' with the actual target column name\n",
    "\n",
    "y = heart_data['condition']\n",
    "\n",
    "heart_data.shape\n",
    "heart_data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:40.742032Z",
     "start_time": "2025-01-23T15:55:39.574754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242, 13)\n",
      "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "132  29.0  1.0  2.0     130.0  204.0  0.0      2.0    202.0    0.0      0.0   \n",
      "202  57.0  1.0  3.0     150.0  126.0  1.0      0.0    173.0    0.0      0.2   \n",
      "196  69.0  1.0  1.0     160.0  234.0  1.0      2.0    131.0    0.0      0.1   \n",
      "75   65.0  0.0  3.0     160.0  360.0  0.0      2.0    151.0    0.0      0.8   \n",
      "176  52.0  1.0  4.0     108.0  233.0  1.0      0.0    147.0    0.0      0.1   \n",
      "\n",
      "     slope   ca thal  \n",
      "132    1.0  0.0  3.0  \n",
      "202    1.0  1.0  7.0  \n",
      "196    2.0  1.0  3.0  \n",
      "75     1.0  0.0  3.0  \n",
      "176    1.0  3.0  7.0  \n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.replace('?', np.nan)\n",
    "X_test = X_test.replace('?', np.nan)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          3\n",
      "thal        2\n",
      "dtype: int64\n",
      "(237, 13)\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isnull().sum())\n",
    "\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train[X_train.index]  # Ensure `y_train` matches the updated `X_train`\n",
    "\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test[X_test.index]  # Ensure `y_test` matches the updated `X_test`\n",
    "\n",
    "heart_data.shape\n",
    "print(X_train.shape)\n",
    "print(X_train.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:56:04.846785Z",
     "start_time": "2025-01-23T15:56:03.481346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Scaling the data.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "model = LogisticRegression(solver='saga', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T16:08:46.099937Z",
     "start_time": "2025-01-23T16:08:46.087946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for new data: [0]\n"
     ]
    }
   ],
   "source": [
    "new_data = X.iloc[3]  # Select the first row from your features\n",
    "new_data = new_data.values.reshape(1, -1)  # Convert to a 2D array\n",
    "new_data = new_data.reshape(1, -1)\n",
    "X_new = pd.DataFrame(new_data, columns=X_train.columns)\n",
    "predictions = model.predict(X_new)\n",
    "print(\"Prediction for new data:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T16:06:56.528712Z",
     "start_time": "2025-01-23T16:06:56.513752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          41.0\n",
       "sex           0.0\n",
       "cp            2.0\n",
       "trestbps    130.0\n",
       "chol        204.0\n",
       "fbs           0.0\n",
       "restecg       2.0\n",
       "thalach     172.0\n",
       "exang         0.0\n",
       "oldpeak       1.4\n",
       "slope         1.0\n",
       "ca            0.0\n",
       "thal          3.0\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:42.292807Z",
     "start_time": "2025-01-23T15:55:42.234539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78        29\n",
      "           1       0.00      0.00      0.00        11\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.11      0.14      0.12         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.43        60\n",
      "   macro avg       0.17      0.20      0.18        60\n",
      "weighted avg       0.36      0.43      0.39        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train decision tree model\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(classification_report(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:43.818992Z",
     "start_time": "2025-01-23T15:55:42.474627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.97      0.84        29\n",
      "           1       0.29      0.18      0.22        11\n",
      "           2       0.12      0.11      0.12         9\n",
      "           3       0.14      0.14      0.14         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.53        60\n",
      "   macro avg       0.26      0.28      0.26        60\n",
      "weighted avg       0.44      0.53      0.48        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train random forest model\n",
    "forest = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Random Forest Performance:\")\n",
    "print(classification_report(y_test, y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         float64\n",
      "sex         float64\n",
      "cp          float64\n",
      "trestbps    float64\n",
      "chol        float64\n",
      "fbs         float64\n",
      "restecg     float64\n",
      "thalach     float64\n",
      "exang       float64\n",
      "oldpeak     float64\n",
      "slope       float64\n",
      "ca           object\n",
      "thal         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtypes)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the training data\n",
    "encoded_train = encoder.fit_transform(X_train[['ca', 'thal']])\n",
    "encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(['ca', 'thal']))\n",
    "\n",
    "# Transform the test data\n",
    "encoded_test = encoder.transform(X_test[['ca', 'thal']])\n",
    "encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(['ca', 'thal']))\n",
    "\n",
    "# Drop the original columns and concatenate the encoded columns\n",
    "X_train = X_train.drop(['ca', 'thal'], axis=1).reset_index(drop=True)\n",
    "X_test = X_test.drop(['ca', 'thal'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train = pd.concat([X_train, encoded_train_df], axis=1)\n",
    "X_test = pd.concat([X_test, encoded_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:45.024492Z",
     "start_time": "2025-01-23T15:55:43.840017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5245901639344263\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        29\n",
      "           1       0.18      0.17      0.17        12\n",
      "           2       0.14      0.11      0.12         9\n",
      "           3       0.29      0.29      0.29         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.27      0.30      0.28        61\n",
      "weighted avg       0.45      0.52      0.48        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming X and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert 'ca' and 'thal' to categorical data type\n",
    "X_train['ca'] = X_train['ca'].astype('category')\n",
    "X_train['thal'] = X_train['thal'].astype('category')\n",
    "\n",
    "X_test['ca'] = X_test['ca'].astype('category')\n",
    "X_test['thal'] = X_test['thal'].astype('category')\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb = XGBClassifier(n_estimators=100, max_depth=4, learning_rate=0.1, random_state=42, enable_categorical=True)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T15:55:45.253418Z",
     "start_time": "2025-01-23T15:55:45.152237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: condition\n",
      "0    9\n",
      "1    9\n",
      "2    9\n",
      "3    9\n",
      "4    9\n",
      "Name: count, dtype: int64\n",
      "(242, 13)\n",
      "(61, 13)\n",
      "Cross-validation scores: [0.11111111 0.22222222 0.22222222 0.11111111 0.33333333]\n",
      "Mean accuracy: 0.2\n",
      "Accuracy: 0.5245901639344263\n",
      "Confusion Matrix:\n",
      "[[24  2  2  1  0]\n",
      " [ 4  1  2  4  1]\n",
      " [ 2  0  4  1  2]\n",
      " [ 0  2  2  2  1]\n",
      " [ 0  1  2  0  1]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        29\n",
      "           1       0.17      0.08      0.11        12\n",
      "           2       0.33      0.44      0.38         9\n",
      "           3       0.25      0.29      0.27         7\n",
      "           4       0.20      0.25      0.22         4\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.35      0.38      0.36        61\n",
      "weighted avg       0.50      0.52      0.51        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Assuming 'heart_data' is your original DataFrame\n",
    "original_column_names = heart_data.columns[:X_train.shape[1]]  # Ensure the column names match the data shape\n",
    "\n",
    "# Convert X_train and X_test to DataFrames\n",
    "X_train = pd.DataFrame(X_train, columns=original_column_names)\n",
    "X_test = pd.DataFrame(X_test, columns=original_column_names)\n",
    "\n",
    "# Replace '?' with NaN\n",
    "X_train = X_train.replace('?', np.nan)\n",
    "X_test = X_test.replace('?', np.nan)\n",
    "\n",
    "# Impute missing values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Corrected here\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Apply SMOTE to resample the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Apply RandomUnderSampler to resample the training data\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Resampled class distribution:\", pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Print shapes of X_train and X_test\n",
    "print(X_train.shape)  # Should return (242, 13)\n",
    "print(X_test.shape)   # Should return the shape of your test data\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(solver='saga', max_iter=10000, class_weight='balanced', C=0.1)\n",
    "scores = cross_val_score(model, X_train_resampled, y_train_resampled, cv=5)\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set target variable counts:\n",
      "condition\n",
      "0    135\n",
      "1     43\n",
      "3     28\n",
      "2     27\n",
      "4      9\n",
      "Name: count, dtype: int64\n",
      "condition\n",
      "0    29\n",
      "1    12\n",
      "2     9\n",
      "3     7\n",
      "4     4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value counts of the target variable in both training and testing sets\n",
    "print(\"Training set target variable counts:\")\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
